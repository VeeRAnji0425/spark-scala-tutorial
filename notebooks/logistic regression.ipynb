{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.BinaryLogisticRegressionSummary\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawData = /home/jovyan/data/stumble_upon/train.tsv MapPartitionsRDD[77] at textFile at <console>:40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/jovyan/data/stumble_upon/train.tsv MapPartitionsRDD[77] at textFile at <console>:40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawData = sc.textFile(\"/home/jovyan/data/stumble_upon/train.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header = \"url\"\t\"urlid\"\t\"boilerplate\"\t\"alchemy_category\"\t\"alchemy_category_score\"\t\"avglinksize\"\t\"commonlinkratio_1\"\t\"commonlinkratio_2\"\t\"commonlinkratio_3\"\t\"commonlinkratio_4\"\t\"compression_ratio\"\t\"embed_ratio\"\t\"framebased\"\t\"frameTagRatio\"\t\"hasDomainLink\"\t\"html_ratio\"\t\"image_ratio\"\t\"is_news\"\t\"lengthyLinkDomain\"\t\"linkwordscore\"\t\"news_front_page\"\t\"non_markup_alphanum_characters\"\t\"numberOfLinks\"\t\"numwords_in_url\"\t\"parametrizedLinkRatio\"\t\"spelling_errors_ratio\"\t\"label\"\n",
       "rawData1 = MapPartitionsRDD[78] at filter at <console>:48\n",
       "records = MapPartitionsRDD[79] at map at <console>:49\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[79] at map at <console>:49"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val header = rawData.first()\n",
    "val rawData1 = rawData.filter(line => line != header)\n",
    "val records = rawData1.map(line => line.split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class StumbleUpon\n",
       "data = MapPartitionsRDD[80] at map at <console>:25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[80] at map at <console>:25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class StumbleUpon(numberOfLinks: Double, numwords_in_url: Double, parametrizedLinkRatio: Double,\n",
    "                       spelling_errors_ratio: Double, label: Int)\n",
    "val data = records.map{ r =>\n",
    "    val trimmed = r.map(_.replaceAll(\"\\\"\", \"\"))\n",
    "    val label = trimmed(r.size - 1).toInt\n",
    "    val features = trimmed.slice(22, r.size - 1).map(d => if (d == \"?\") 0.0 else d.toDouble)\n",
    "    assert(features.size == 4)\n",
    "    StumbleUpon(features(0), features(1), features(2), features(3), label)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StumbleUpon(170.0,8.0,0.152941176,0.079129575,0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataDF = [numberOfLinks: double, numwords_in_url: double ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[numberOfLinks: double, numwords_in_url: double ... 3 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataDF = data.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------------+---------------------+-----+\n",
      "|numberOfLinks|numwords_in_url|parametrizedLinkRatio|spelling_errors_ratio|label|\n",
      "+-------------+---------------+---------------------+---------------------+-----+\n",
      "|        170.0|            8.0|          0.152941176|          0.079129575|    0|\n",
      "|        187.0|            9.0|          0.181818182|          0.125448029|    1|\n",
      "|        258.0|           11.0|          0.166666667|          0.057613169|    1|\n",
      "+-------------+---------------+---------------------+---------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "featureCols = Array(numberOfLinks, numwords_in_url, parametrizedLinkRatio, spelling_errors_ratio)\n",
       "assembler = vecAssembler_6d3fd382cc34\n",
       "df2 = [numberOfLinks: double, numwords_in_url: double ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[numberOfLinks: double, numwords_in_url: double ... 4 more fields]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featureCols = Array(\"numberOfLinks\", \"numwords_in_url\", \"parametrizedLinkRatio\", \"spelling_errors_ratio\")\n",
    "val assembler = new VectorAssembler().setInputCols(featureCols).setOutputCol(\"features\")\n",
    "val df2 = assembler.transform(dataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+\n",
      "|numberOfLinks|numwords_in_url|parametrizedLinkRatio|spelling_errors_ratio|label|            features|\n",
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+\n",
      "|        170.0|            8.0|          0.152941176|          0.079129575|    0|[170.0,8.0,0.1529...|\n",
      "|        187.0|            9.0|          0.181818182|          0.125448029|    1|[187.0,9.0,0.1818...|\n",
      "|        258.0|           11.0|          0.166666667|          0.057613169|    1|[258.0,11.0,0.166...|\n",
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "splitSeed = 5043\n",
       "trainingData = [numberOfLinks: double, numwords_in_url: double ... 4 more fields]\n",
       "testData = [numberOfLinks: double, numwords_in_url: double ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[numberOfLinks: double, numwords_in_url: double ... 4 more fields]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val splitSeed = 5043\n",
    "val Array(trainingData, testData) = df2.randomSplit(Array(0.7, 0.3), splitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr = logreg_dbc1f91d4603\n",
       "model = logreg_dbc1f91d4603\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_dbc1f91d4603"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "val model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions = [numberOfLinks: double, numwords_in_url: double ... 7 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[numberOfLinks: double, numwords_in_url: double ... 7 more fields]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|numberOfLinks|numwords_in_url|parametrizedLinkRatio|spelling_errors_ratio|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|          1.0|            2.0|                  0.0|          0.063270991|    1|[1.0,2.0,0.0,0.06...|[-0.0370059391125...|[0.49074957085638...|       1.0|\n",
      "|          2.0|            0.0|                  0.0|          0.105263158|    0|[2.0,0.0,0.0,0.10...|[-0.0370059391125...|[0.49074957085638...|       1.0|\n",
      "|          2.0|            1.0|                  0.0|          0.089552239|    0|[2.0,1.0,0.0,0.08...|[-0.0370059391125...|[0.49074957085638...|       1.0|\n",
      "+-------------+---------------+---------------------+---------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929760299168406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trainingSummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummaryImpl@7c65e2f8\n",
       "objectiveHistory = Array(0.6929760299168406)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.6929760299168406]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingSummary = model.summary\n",
    "val objectiveHistory = trainingSummary.objectiveHistory\n",
    "objectiveHistory.foreach(loss => println(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binarySummary = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummaryImpl@7c65e2f8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummaryImpl@7c65e2f8"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val binarySummary = trainingSummary.asInstanceOf[BinaryLogisticRegressionSummary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|FPR|TPR|\n",
      "+---+---+\n",
      "|0.0|0.0|\n",
      "|1.0|1.0|\n",
      "|1.0|1.0|\n",
      "+---+---+\n",
      "\n",
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "roc = [FPR: double, TPR: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[FPR: double, TPR: double]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val roc = binarySummary.roc\n",
    "roc.show()\n",
    "println(binarySummary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fMeasure = [threshold: double, F-Measure: double]\n",
       "fm = F-Measure\n",
       "maxFMeasure = 0.674838872741059\n",
       "bestThreshold = 0.5092504291436201\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "logreg_dbc1f91d4603"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Set the model threshold to maximize F-Measure\n",
    "val fMeasure = binarySummary.fMeasureByThreshold\n",
    "val fm = fMeasure.col(\"F-Measure\")\n",
    "val maxFMeasure = fMeasure.select(max(\"F-Measure\")).head().getDouble(0)\n",
    "val bestThreshold = fMeasure.where($\"F-Measure\" === maxFMeasure).select(\"threshold\").head().getDouble(0)\n",
    "model.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluator = binEval_033132bf8cec\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "binEval_033132bf8cec"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val evaluator = new BinaryClassificationEvaluator().setLabelCol(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy = 0.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val accuracy = evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
